{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" I am attempting to make a model out of this research paper on \n",
    "MULTI-VIEW GAIT RECOGNITION USING 3D CONVOLUTIONAL NEURAL NETWORKS. it's my first time, that I am\n",
    "building a model from scratch. I am excited to use Keras for this purpose.\"\"\"\n",
    "\n",
    "\"\"\"The prerequisites:\n",
    "1. Keras, Tensorflow, Python, Numpy, Matplotlib, pandas\n",
    "2. Reading and analysing the research papers\n",
    "3. Knowledge of 3D convolution neural networks\n",
    "4. CASIA_B Dataset and it's ordering and structuring inside the given zip file\n",
    "5. A lot of faith in one's self and willing to take risk with one's time!\n",
    "\n",
    "So if you have done this, cheers! Let's go!\"\"\"\n",
    "\n",
    "\"\"\"Important points:\n",
    "1. Referring to https://towardsdatascience.com/\n",
    "step-by-step-implementation-3d-convolutional-neural-network-in-keras-12efbdd7b130\n",
    "\n",
    "2. I am taking 20 images out of the 6 walking sequences from each of the 11 viewing angles in \n",
    "normal/cooperative conditions for 124 total subjects\n",
    "\n",
    "3. I have taken 20 more images out of the same above given categories for my testing data\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"I will be noting the experiment count here: \"\"\"\n",
    "count = 9\n",
    "print(\"This is experiment number: \",count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "import cv2\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv3D\n",
    "from keras.layers import AveragePooling2D, MaxPooling3D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the time taken to parse and restructure the dataset is : 61.095455169677734 seconds\n"
     ]
    }
   ],
   "source": [
    "# structuring the data\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "time_step=0\n",
    "frames=[]\n",
    "filepath=r\"D:\\dataScience\\machine-learning-online-2018-master\\Datasets\\GaitDatasetB-silh\"\n",
    "condition=\"nm-01\"\n",
    "start=time.time()\n",
    "for person in os.listdir(filepath):\n",
    "    mainpath=os.path.join(filepath,person,condition)\n",
    "    for view in os.listdir(mainpath):\n",
    "        total_path=os.path.join(mainpath,view)\n",
    "        count=0\n",
    "        for i,image in enumerate(os.listdir(total_path)):\n",
    "            orig=Image.open(os.path.join(total_path,image))\n",
    "            orig=orig.resize((128,192))\n",
    "            img=Image.new(\"RGB\",orig.size)\n",
    "            img.paste(orig)\n",
    "            if time_step==16:\n",
    "                if i<18: # can be any random number less than 32 actually as it's just a check!\n",
    "                    X_train.append(np.asarray(frames))\n",
    "                    Y_train.append(int(person.strip())-1)\n",
    "                \n",
    "                else:\n",
    "                    X_test.append(np.asarray(frames))\n",
    "                    Y_test.append(int(person.strip())-1)\n",
    "                time_step=0\n",
    "                frames=[]\n",
    "                count+=1\n",
    "            \n",
    "            if count==2:\n",
    "                break\n",
    "                \n",
    "            frames.append(np.asarray(img))\n",
    "            time_step+=1\n",
    "        \n",
    "end=time.time()\n",
    "\n",
    "print(\"the time taken to parse and restructure the dataset is : {0} seconds\".format(end-start))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to numpy arrays\n",
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "X_test=np.array(X_test)\n",
    "Y_test=np.array(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12  62  61  74  36  68  58   4 112 116]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.permutation(len(X_train))\n",
    "X_train,Y_train = X_train[idx], Y_train[idx]\n",
    "print(Y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 64  28  93  86  59  25 110  54  95  36]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.permutation(len(X_test))\n",
    "X_test,Y_test = X_test[idx], Y_test[idx]\n",
    "print(Y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]]\n",
      "\n",
      "\n",
      " [[[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]\n",
      "\n",
      "  [[0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   ...\n",
      "   [0 0 0]\n",
      "   [0 0 0]\n",
      "   [0 0 0]]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1353, 16, 192, 128, 3)\n",
      "(1353,)\n",
      "(1346, 16, 192, 128, 3)\n",
      "(1346,)\n"
     ]
    }
   ],
   "source": [
    "#X_train = rgb_data_transform(X_train)\n",
    "#X_test = rgb_data_transform(X_test)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "# Convert target vectors to categorical targets\n",
    "targets_train = to_categorical(Y_train).astype(np.integer)\n",
    "targets_test = to_categorical(Y_test).astype(np.integer)\n",
    "#dictating the sample shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1353, 124)\n",
      "(1346, 124)\n"
     ]
    }
   ],
   "source": [
    "print(targets_train.shape)\n",
    "print(targets_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creating and Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping X_train a little bit\n",
    "X_train=np.swapaxes(X_train,1,2)\n",
    "X_train=np.swapaxes(X_train,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1353, 192, 128, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 192, 128, 16, 64)  5248      \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 96, 64, 16, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 96, 64, 16, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 48, 32, 8, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 48, 32, 8, 128)    442496    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 24, 16, 8, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 24, 16, 8, 256)    884992    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 12, 8, 4, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 12, 8, 4, 256)     1769728   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 6, 4, 2, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 6, 4, 2, 512)      3539456   \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 6, 4, 2, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 3, 2, 1, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              12587008  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 124)               508028    \n",
      "=================================================================\n",
      "Total params: 43,817,980\n",
      "Trainable params: 43,817,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "#layer1\n",
    "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding='same', data_format='channels_last', kernel_initializer='he_uniform', \n",
    "                 input_shape=(192,128,16,3))) \n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 1), data_format='channels_last'))\n",
    "#layer2\n",
    "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding='same', \n",
    "                 data_format='channels_last', kernel_initializer='he_uniform' ))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), data_format='channels_last'))\n",
    "#layer3\n",
    "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding='same', data_format='channels_last', \n",
    "                 kernel_initializer='he_uniform' ))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 1), data_format='channels_last'))\n",
    "#layer4\n",
    "model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu', padding='same', data_format='channels_last', \n",
    "                 kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), data_format='channels_last'))\n",
    "#layer5\n",
    "model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu', padding='same', data_format='channels_last', \n",
    "                 kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), data_format='channels_last'))\n",
    "#layer6\n",
    "model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu', padding='same', data_format='channels_last', \n",
    "                 kernel_initializer='he_uniform'))\n",
    "#layer7\n",
    "model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu', padding='same', data_format='channels_last', \n",
    "                 kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), data_format='channels_last'))\n",
    "#flattening\n",
    "model.add(Flatten())\n",
    "#FC layer 1\n",
    "model.add(Dense(4096, activation='relu', kernel_initializer='he_uniform', \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
    "model.add(Dropout(0.5))\n",
    "#FC Layer 2\n",
    "model.add(Dense(4096, activation='relu', kernel_initializer='he_uniform',  \n",
    "                kernel_regularizer=tf.keras.regularizers.l2(0.0005)))\n",
    "model.add(Dropout(0.5))\n",
    "# making a softmax function\n",
    "model.add(Dense(124, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Fit data to model\n",
    "history = model.fit(X_train, targets_train,\n",
    "            batch_size=16,\n",
    "            epochs=40,\n",
    "            verbose=1,\n",
    "            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test,targets_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
